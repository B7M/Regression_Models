<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Week 03 | Course Name</title>
  <meta name="description" content="Description about Course/Book." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Week 03 | Course Name" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Description about Course/Book." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Week 03 | Course Name" />
  
  <meta name="twitter:description" content="Description about Course/Book." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/dasl_favicon.ico" type="image/x-icon" />
<link rel="prev" href="week-02.html"/>
<link rel="next" href="week-04.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="assets/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<a href="http://jhudatascience.org/"><img src="https://jhudatascience.org/images/dasl.png" style=" width: 80%; padding-left: 40px; padding-top: 8px; vertical-align: top "</a>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Course</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#available-course-formats"><i class="fa fa-check"></i><b>0.1</b> Available course formats</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="week-01.html"><a href="week-01.html"><i class="fa fa-check"></i><b>1</b> Week 01</a>
<ul>
<li class="chapter" data-level="1.1" data-path="week-01.html"><a href="week-01.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="week-01.html"><a href="week-01.html#welcome-to-regression-models"><i class="fa fa-check"></i><b>1.1.1</b> Welcome to Regression Models</a></li>
<li class="chapter" data-level="1.1.2" data-path="week-01.html"><a href="week-01.html#some-basics"><i class="fa fa-check"></i><b>1.1.2</b> Some Basics</a></li>
<li class="chapter" data-level="1.1.3" data-path="week-01.html"><a href="week-01.html#syllabus-xxx"><i class="fa fa-check"></i><b>1.1.3</b> Syllabus (xxx)</a></li>
<li class="chapter" data-level="1.1.4" data-path="week-01.html"><a href="week-01.html#data-science-specialization-community-site"><i class="fa fa-check"></i><b>1.1.4</b> Data Science Specialization Community Site</a></li>
<li class="chapter" data-level="1.1.5" data-path="week-01.html"><a href="week-01.html#where-to-get-more-advanced-material"><i class="fa fa-check"></i><b>1.1.5</b> Where to get more advanced material</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="week-01.html"><a href="week-01.html#introduction-to-regression-and-least-squares"><i class="fa fa-check"></i><b>1.2</b> Introduction to regression and least squares</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="week-01.html"><a href="week-01.html#introduction-to-regression"><i class="fa fa-check"></i><b>1.2.1</b> Introduction to Regression</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="week-01.html"><a href="week-01.html#linear-least-squares"><i class="fa fa-check"></i><b>1.3</b> Linear least squares</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="week-01.html"><a href="week-01.html#notations-and-background"><i class="fa fa-check"></i><b>1.3.1</b> Notations and background</a></li>
<li class="chapter" data-level="1.3.2" data-path="week-01.html"><a href="week-01.html#linear-least-squares-1"><i class="fa fa-check"></i><b>1.3.2</b> Linear Least Squares</a></li>
<li class="chapter" data-level="1.3.3" data-path="week-01.html"><a href="week-01.html#linear-least-squares-coding-example"><i class="fa fa-check"></i><b>1.3.3</b> Linear Least Squares Coding Example</a></li>
<li class="chapter" data-level="1.3.4" data-path="week-01.html"><a href="week-01.html#mathematical-details-optional-xxx"><i class="fa fa-check"></i><b>1.3.4</b> Mathematical Details (Optional) XXX</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="week-01.html"><a href="week-01.html#regression-to-the-mean"><i class="fa fa-check"></i><b>1.4</b> Regression to the Mean</a></li>
<li class="chapter" data-level="1.5" data-path="week-01.html"><a href="week-01.html#practical-r-exercises-in-swirl"><i class="fa fa-check"></i><b>1.5</b> Practical R Exercises in swirl</a></li>
<li class="chapter" data-level="1.6" data-path="week-01.html"><a href="week-01.html#week-1-quiz"><i class="fa fa-check"></i><b>1.6</b> Week 1 Quiz</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="week-02.html"><a href="week-02.html"><i class="fa fa-check"></i><b>2</b> Week 02</a>
<ul>
<li class="chapter" data-level="2.1" data-path="week-02.html"><a href="week-02.html#statistical-linear-regression-models"><i class="fa fa-check"></i><b>2.1</b> Statistical linear regression models</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="week-02.html"><a href="week-02.html#statistical-linear-regression-models-1"><i class="fa fa-check"></i><b>2.1.1</b> Statistical Linear Regression Models</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="week-02.html"><a href="week-02.html#residuals"><i class="fa fa-check"></i><b>2.2</b> Residuals</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="week-02.html"><a href="week-02.html#optional-reading-how-to-derive-r-squared"><i class="fa fa-check"></i><b>2.2.1</b> Optional reading How to derive R squared:</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="week-02.html"><a href="week-02.html#inference-in-regression"><i class="fa fa-check"></i><b>2.3</b> Inference in regression</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="week-02.html"><a href="week-02.html#prediction"><i class="fa fa-check"></i><b>2.3.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="week-02.html"><a href="week-02.html#for-the-project"><i class="fa fa-check"></i><b>2.4</b> For the project</a></li>
<li class="chapter" data-level="2.5" data-path="week-02.html"><a href="week-02.html#practical-r-exercises-in-swirl-1"><i class="fa fa-check"></i><b>2.5</b> Practical R Exercises in swirl</a></li>
<li class="chapter" data-level="2.6" data-path="week-02.html"><a href="week-02.html#week-2-quiz"><i class="fa fa-check"></i><b>2.6</b> Week 2 Quiz</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="week-03.html"><a href="week-03.html"><i class="fa fa-check"></i><b>3</b> Week 03</a>
<ul>
<li class="chapter" data-level="3.1" data-path="week-03.html"><a href="week-03.html#multi-variable-regression"><i class="fa fa-check"></i><b>3.1</b> Multi-variable regression</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="week-03.html"><a href="week-03.html#how-to-get-the-coefficients-derivation-of-formulas"><i class="fa fa-check"></i><b>3.1.1</b> How to get the coefficients, derivation of formulas</a></li>
<li class="chapter" data-level="3.1.2" data-path="week-03.html"><a href="week-03.html#results"><i class="fa fa-check"></i><b>3.1.2</b> Results</a></li>
<li class="chapter" data-level="3.1.3" data-path="week-03.html"><a href="week-03.html#example-with-two-variables-simple-linear-regression"><i class="fa fa-check"></i><b>3.1.3</b> Example with two variables, simple linear regression</a></li>
<li class="chapter" data-level="3.1.4" data-path="week-03.html"><a href="week-03.html#the-general-case"><i class="fa fa-check"></i><b>3.1.4</b> The general case</a></li>
<li class="chapter" data-level="3.1.5" data-path="week-03.html"><a href="week-03.html#examples-with-multiple-variables"><i class="fa fa-check"></i><b>3.1.5</b> Examples with multiple-variables</a></li>
<li class="chapter" data-level="3.1.6" data-path="week-03.html"><a href="week-03.html#interpretation-of-coefficients"><i class="fa fa-check"></i><b>3.1.6</b> Interpretation of coefficients</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="week-03.html"><a href="week-03.html#multi-variable-regression-tips-and-tricks"><i class="fa fa-check"></i><b>3.2</b> Multi-variable regression tips and tricks</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="week-03.html"><a href="week-03.html#dummy-variables-are-smart"><i class="fa fa-check"></i><b>3.2.1</b> Dummy variables are smart</a></li>
<li class="chapter" data-level="3.2.2" data-path="week-03.html"><a href="week-03.html#summary-of-the-insectsprays-example"><i class="fa fa-check"></i><b>3.2.2</b> Summary of the InsectSprays example</a></li>
<li class="chapter" data-level="3.2.3" data-path="week-03.html"><a href="week-03.html#exploring-the-models-in-r"><i class="fa fa-check"></i><b>3.2.3</b> Exploring the models in R</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="week-03.html"><a href="week-03.html#adjustment"><i class="fa fa-check"></i><b>3.3</b> Adjustment</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="week-03.html"><a href="week-03.html#adjustment-examples"><i class="fa fa-check"></i><b>3.3.1</b> Adjustment Examples</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="week-03.html"><a href="week-03.html#residuals-again"><i class="fa fa-check"></i><b>3.4</b> Residuals again</a></li>
<li class="chapter" data-level="3.5" data-path="week-03.html"><a href="week-03.html#model-selection"><i class="fa fa-check"></i><b>3.5</b> Model selection</a></li>
<li class="chapter" data-level="3.6" data-path="week-03.html"><a href="week-03.html#practical-r-exercises-in-swirl-2"><i class="fa fa-check"></i><b>3.6</b> Practical R Exercises in swirl</a></li>
<li class="chapter" data-level="3.7" data-path="week-03.html"><a href="week-03.html#week-3-quiz"><i class="fa fa-check"></i><b>3.7</b> Week 3 Quiz</a></li>
<li class="chapter" data-level="3.8" data-path="week-03.html"><a href="week-03.html#optional-practice-exercise-in-regression-modeling"><i class="fa fa-check"></i><b>3.8</b> (OPTIONAL) Practice exercise in regression modeling</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-04.html"><a href="week-04.html"><i class="fa fa-check"></i><b>4</b> Week 04</a>
<ul>
<li class="chapter" data-level="4.1" data-path="week-04.html"><a href="week-04.html#glm"><i class="fa fa-check"></i><b>4.1</b> GLM</a></li>
<li class="chapter" data-level="4.2" data-path="week-04.html"><a href="week-04.html#logistic-regression"><i class="fa fa-check"></i><b>4.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.3" data-path="week-04.html"><a href="week-04.html#poisson-regression"><i class="fa fa-check"></i><b>4.3</b> Poisson Regression</a></li>
<li class="chapter" data-level="4.4" data-path="week-04.html"><a href="week-04.html#hodgepodge"><i class="fa fa-check"></i><b>4.4</b> Hodgepodge</a></li>
<li class="chapter" data-level="4.5" data-path="week-04.html"><a href="week-04.html#practical-r-exercises-in-swirl-3"><i class="fa fa-check"></i><b>4.5</b> Practical R Exercises in swirl</a></li>
<li class="chapter" data-level="4.6" data-path="week-04.html"><a href="week-04.html#week-4-quiz"><i class="fa fa-check"></i><b>4.6</b> Week 4 Quiz</a></li>
<li class="chapter" data-level="4.7" data-path="week-04.html"><a href="week-04.html#course-project-1"><i class="fa fa-check"></i><b>4.7</b> Course Project</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="5" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>5</b> References</a></li>
<li class="divider"></li>
<p style="text-align:center;"> <a href="https://github.com/jhudsl/OTTR_Template" target="blank" > This content was published with</a> <a href="https://bookdown.org/" target="blank"> bookdown by:</a> </p>
<p style="text-align:center;"> <a href="http://jhudatascience.org/"> The Johns Hopkins Data Science Lab </a></p>
<p style="text-align:center; font-size: 12px;"> <a href="https://github.com/rstudio4edu/rstudio4edu-book/"> Style adapted from: rstudio4edu-book </a> <a href ="https://creativecommons.org/licenses/by/2.0/"> (CC-BY 2.0) </a></p>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Course Name</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=1.0,initial-scale=1.0">
  <!--script src="https://kit.fontawesome.com/6a26f47516.js"></script-->
  <!--<script src="assets/hideOutput.js"></script>-->
  <link href="assets/style.css" rel="stylesheet">
</head>



<div class="hero-image-container">
  <img class= "hero-image" src= "https://github.com/jhudsl/OTTR_Template/raw/main/assets/dasl_thin_main_image.png">
</div>
<div id="week-03" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Week 03</h1>
<div id="multi-variable-regression" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Multi-variable regression</h2>
<p>We now extend linear regression so that our models can contain more variables. A natural first approach is to assume additive effects, basically extending our line to a plane, or generalized version of a plane as we add more variables. Multi-variable regression represents one of the most widely used and successful methods in statistics.</p>
<p>If you’re utilizing predictor X to forecast a response Y and discover a meaningful relationship, there’s a potential issue if the predictor hasn’t been randomly assigned to the subjects or units being observed. In such cases, there’s always a concern that there might be another variable, whether known or unknown, that could account for the observed relationship. For example, imagine if you had a friend who downloaded some data, where they had all sorts of health information from people
and also their dietary information. This person claims to have found an interesting relationship: breath mint usage has a significant regression relationship with forced expiratory volume(FEV), a measure of lung function. You would be skeptical there’s very little basis for a biological relationship there. Breath mints are just sugar! But maybe, but what you’ve really be thinking is what other variables might explain this relationship? You might have two hypotheses: this person dug through lots and lots of variables and just found the one that was significant, and it’s just a chance of association, which is the problem of multiplicity. In addition it is likely, you would think the real problem is smokers tend to use more breath mints, and smoking has this relationship with lung function. It’s well-established that chronic exposure to a smoker, even second-hand smoke has negative impacts on lung function. So it’s probably smoking it probably has nothing to do with the breath mints, it’s a indirect effect of breath mints through smoking, not a direct effect of breath mints on lung function. This would be the hypothesis. To establish that there’s a breath mint effect beyond smoking we could consider smokers by themselves, and see whether their lung function differs by their breath mint usage, and consider non-smokers by themselves, and see whether their lung function differs by breath mint usage, where we conditioned on smoking status. This way we would compare like with like. Multivariable regression is sort of automated way to do that in a linear fashion. It makes fair enough assumptions, in automated way. In this section we will explain how it works and we will also talk a little bit about its limitations.</p>
<p>Multivariable regression is trying to look at the relationship of a predictor and a response, while having, at some level, accounted for other variables. Moreover, multivariable regression is actually a good prediction model.
For example, a Kaggle competition wanted to predict the number of days a person would be in the hospital in subsequent years given their claims history and number of days they were in the hospital in previous years. The insurance companies seek to harness an extensive dataset derived from claims, aiming to predict a singular numerical outcome. However, the conventional approach of simple linear regression would be insufficient when confronted with multiple predictors. How can we extend the scope of simple linear regression to accommodate a multitude of regressors for predictive purposes? The procedure is similar to simple linear regression where there’s more predictor terms, X values. For example, <span class="math inline">\(X_1\)</span> might be the number of insurance claims in the previous year, and <span class="math inline">\(X_2\)</span> might be whether or not the person had a particular cardiac problem, and so on. The first variable is typically just a constant one, so there’s an intercept that’s included, a term that’s just <span class="math inline">\(\beta_0\)</span> by itself. Interestingly in this competition, we found that multivariable regression could get people very close to the winning entry, while other machine learning methods like random forest, and boosting only improved the results minorly on top of multivariable regression.</p>
<p>Note: in case of breath mint study, one of the predictors, <span class="math inline">\(X_1\)</span> might be breath mint usage (a binary variable), and <span class="math inline">\(X_2\)</span> might be how much a person smoked.</p>
<ul>
<li><p>The general linear model extends simple linear regression (SLR) by adding terms linearly into the model.
<span class="math display">\[
Y_i =  \beta_0 X_{0i} + \beta_1 X_{1i} + \ldots +
\beta_{p} X_{pi} + \epsilon_{i} 
= \sum_{k=0}^p X_{ik} \beta_j + \epsilon_{i}
\]</span></p></li>
<li><p>Where <span class="math inline">\(X_{1i}=1\)</span> typically, the <span class="math inline">\(\beta_j\)</span> are the coefficients of the model.</p></li>
<li><p>Least squares (and hence ML estimates under iid Gaussianity of the errors) minimizes
<span class="math display">\[
\sum_{i=1}^n \left(Y_i - \sum_{k=1}^p X_{ki} \beta_j\right)^2
\]</span>
Note, the important linearity is linearity in the coefficients. Thus
<span class="math display">\[
Y_i =  \beta_1 X_{1i}^2 + \beta_2 X_{2i}^2 + \ldots +
\beta_{p} X_{pi}^2 + \epsilon_{i} 
\]</span>
is still a linear model. (We’ve just squared the elements of the predictor variables.)</p></li>
</ul>
<div id="how-to-get-the-coefficients-derivation-of-formulas" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> How to get the coefficients, derivation of formulas</h3>
<p>Here we will go through the derivation of formulas to show how the least squares estimates are obtained. This derivation is not required for the course, but it may be helpful for those who are interested in understanding how the estimates are obtained.</p>
<p>Just to review, if you have regression to the origin, you want a line that’s forced to the origin that has no intercepts. You have the single predictor <span class="math inline">\(X\)</span> and a single predictor of <span class="math inline">\(Y\)</span> and you want no intercept, <span class="math inline">\(E[Y_i]=X_{1i}\beta_1\)</span>. The slope estimate was <span class="math inline">\(\sum X_i Y_i / \sum X_i^2\)</span>. Now lets try to derive the least squares estimate when we have two regressors, which can be generalized to models with more variables. In <span class="math inline">\(E[Y_i] = X_{1i}\beta_1 + X_{2i}\beta_2 = \mu_i\)</span>, Least squares tries to minimize:
<span class="math display">\[
\sum_{i=1}^n (Y_i - X_{1i} \beta_1 - X_{2i} \beta_2)^2
\]</span>
Here we try to give a development that is more intuitive than what you would get with something like linear algebra.
<span class="math display">\[\Sum(y_i - X_{0i} \beta_0 - X_{1i} \beta_1\]</span>
Imagine we knew <span class="math inline">\(\beta_1\)</span> or fix <span class="math inline">\(\beta_1\)</span>, then we can write <span class="math inline">\(\tilde y_i = y_i - x_{0i} \beta_0\)</span> and subsequently <span class="math inline">\(\Sum(\tilde y_i - X_{1i} \beta_1\)</span>. This is exactly regression through the origin with just the single regressor. So we can write <span class="math inline">\(\beta_1 = \sum \tilde y_i X_{1i} / \sum X_{1i}^2\)</span>. Now we can plug this back into the original equation and we get:
<span class="math display">\[
\sum_{i=1}^n (Y_i - X_{1i} \beta_1 - X_{2i} \sum \tilde y_i X_{1i} / \sum X_{1i}^2)^2
\]</span>
This is an equation that only involves <span class="math inline">\(\beta_0\)</span> and a regression through the origin for <span class="math inline">\(\beta_0\)</span>. What it works out to be, and this is the interesting part, is that the regression slope for <span class="math inline">\(\beta_0\)</span>, is exactly what you would obtain if you took the residual of <span class="math inline">\(X_1\)</span> out of <span class="math inline">\(X_0\)</span>, and <span class="math inline">\(X_1\)</span> out of <span class="math inline">\(Y\)</span> and
then just did regression to the origin.</p>
<p>Multivariable regression calculates the coefficient for <span class="math inline">\(X_0\)</span>, <span class="math inline">\(\beta_0\)</span>, as if you had removed the effect of <span class="math inline">\(X_1\)</span> from both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_0\)</span>. Similarly, the regression coefficient for <span class="math inline">\(X_1\)</span>, <span class="math inline">\(\beta_1\)</span>, is what you would get if you were to remove the effect of <span class="math inline">\(X_0\)</span> from both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1\)</span>. This is why multivariable regression is thought of as having adjusted for the other variables.
A coefficient from a multivariable regression is the coefficient where the linear effect of all the other variables on that predictor and response has been removed.</p>
</div>
<div id="results" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Results</h3>
<p>In <span class="math inline">\(E[Y_i] = X_{0i}\beta_0 + X_{1i}\beta_1\)</span>, we have two covariates, <span class="math inline">\(X_1 , X_2\)</span>.
<span class="math display">\[\hat \beta_0 = \frac{\sum_{i=1}^n e_{i, Y | X_1} e_{i, X_0 | X_1}}{\sum_{i=1}^n e_{i, X_0 | X_1}^2}\]</span></p>
<p><span class="math inline">\(\beta_0\)</span> is what you would get with regression through the origin if you removed the second coefficient <span class="math inline">\(X_1\)</span>. Similarly, the same thing could be said about the coefficient for <span class="math inline">\(X_1 \beta_1\)</span>. <span class="math inline">\(\hat \beta_1\)</span> is the linear regression where linear effect of <span class="math inline">\(X_0\)</span> out of both the response <span class="math inline">\(Y\)</span>, and the second predictor, <span class="math inline">\(X_1\)</span>. This is why multivariable regression relationships are considered as having been adjusted for all the other variables.</p>
</div>
<div id="example-with-two-variables-simple-linear-regression" class="section level3" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Example with two variables, simple linear regression</h3>
<p><span class="math inline">\(Y_{i} = \beta_0 X_{0i} + \beta_1 X_{1i}\)</span> where <span class="math inline">\(X_{0i} = 1\)</span> is an intercept term. Notice the fitted coefficient of <span class="math inline">\(X_{1i}\)</span> on <span class="math inline">\(Y_{i}\)</span> is <span class="math inline">\(\bar Y\)</span>. The residuals are <span class="math inline">\(e_{i, Y | X_1} = Y_i - \bar Y\)</span>. Thus the fitted coefficient of <span class="math inline">\(X_{1i}\)</span> on <span class="math inline">\(X_{0i}\)</span> is <span class="math inline">\(\bar X_1\)</span>, which is the residuals <span class="math inline">\(e_{i, X_0 | X_1}= X_{0i} - \bar X_0\)</span>. We can write:
<span class="math display">\[
\hat \beta_1 = \frac{\sum_{i=1}^n e_{i, Y | X_0} e_{i, X_1 | X_0}}{\sum_{i=1}^n e_{i, X_1 | X_0}^2} = \frac{\sum_{i=1}^n (X_i - \bar X)(Y_i - \bar Y)}{\sum_{i=1}^n (X_i - \bar X)^2}
= Cor(X, Y) \frac{Sd(Y)}{Sd(X)}
\]</span></p>
</div>
<div id="the-general-case" class="section level3" number="3.1.4">
<h3><span class="header-section-number">3.1.4</span> The general case</h3>
<p>More generally, multivariate regression estimates are exactly those having removed the linear relationship of the other variables from both the regressor and response. Least squares solutions have to minimize<span class="math display">\[\sum_{i=1}^n (Y_i - X_{1i}\beta_1 - \ldots - X_{pi}\beta_p)^2\]</span>. The least squares estimate for the coefficient of a multivariate regression model is exactly regression through the origin with the linear relationships with the other regressors removed from both the regressor and outcome by taking residuals. In this sense, multivariate regression “adjusts” a coefficient for the linear impact of the other variables.</p>
</div>
<div id="examples-with-multiple-variables" class="section level3" number="3.1.5">
<h3><span class="header-section-number">3.1.5</span> Examples with multiple-variables</h3>
<p>In the following simulation we have 100 observations and want to generate three predictors, <code>x, x2, x3</code>, where they are all just standard normal. When we write <code>y = 1 + x + x2 + x3</code>, all my coefficients are 1, meaning the population model used for simulation, they’re all 1. Next we add some random noise, that’s the error term.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="week-03.html#cb124-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">100</span>; x <span class="ot">=</span> <span class="fu">rnorm</span>(n); x2 <span class="ot">=</span> <span class="fu">rnorm</span>(n); x3 <span class="ot">=</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb124-2"><a href="week-03.html#cb124-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="dv">1</span> <span class="sc">+</span> x <span class="sc">+</span> x2 <span class="sc">+</span> x3 <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> .<span class="dv">1</span>)</span>
<span id="cb124-3"><a href="week-03.html#cb124-3" aria-hidden="true" tabindex="-1"></a>ey <span class="ot">=</span> <span class="fu">resid</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x2 <span class="sc">+</span> x3))</span>
<span id="cb124-4"><a href="week-03.html#cb124-4" aria-hidden="true" tabindex="-1"></a>ex <span class="ot">=</span> <span class="fu">resid</span>(<span class="fu">lm</span>(x <span class="sc">~</span> x2 <span class="sc">+</span> x3))</span>
<span id="cb124-5"><a href="week-03.html#cb124-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(ey <span class="sc">*</span> ex) <span class="sc">/</span> <span class="fu">sum</span>(ex <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb124-6"><a href="week-03.html#cb124-6" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(ey <span class="sc">~</span> ex <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb124-7"><a href="week-03.html#cb124-7" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> x2 <span class="sc">+</span> x3)) </span></code></pre></div>
<p>Here we want to point out, <code>coef(lm(ey ~ ex - 1))</code> is the same coefficient as if we regress y on x, x2 and x3, and an intercept <code>coef(lm(y ~ x + x2 + x3))</code>. You see the x term here is exactly the same as the regression through the origin estimate with the residuals.</p>
</div>
<div id="interpretation-of-coefficients" class="section level3" number="3.1.6">
<h3><span class="header-section-number">3.1.6</span> Interpretation of coefficients</h3>
<p>The regression predictor, given the collection of covariants take a specific value, <span class="math inline">\(x_1\)</span> to <span class="math inline">\(x_p\)</span>, is just the sum of the <span class="math inline">\(x_k\beta_k\)</span>. <span class="math display">\[E[Y | X_1 = x_1, \ldots, X_p = x_p] = \sum_{k=1}^p x_{k} \beta_k\]</span></p>
<p>If one of the predictors, say <span class="math inline">\(X_1\)</span>, is incremented by 1 i.e. <span class="math inline">\(X_1\)</span> instead of <span class="math inline">\(x_1\)</span> takes <span class="math inline">\(x_1+1\)</span>, then the regression coefficient <span class="math inline">\(\beta_1\)</span> is the expected change in the response.
<span class="math display">\[
E[Y | X_1 = x_1 + 1, \ldots, X_p = x_p] = (x_1 + 1) \beta_1 + \sum_{k=2}^p x_{k} \beta_k
\]</span></p>
<p>If we subtract the two terms the expected value of the response from the responce where the first co-efficient takes the value of <span class="math inline">\(x_1 +1\)</span> works out to be <span class="math inline">\(\beta_1\)</span>.
<span class="math display">\[
E[Y | X_1 = x_1 + 1, \ldots, X_p = x_p]  - E[Y | X_1 = x_1, \ldots, X_p = x_p]\]</span>
<span class="math display">\[= (x_1 + 1) \beta_1 + \sum_{k=2}^p x_{k} \beta_k + \sum_{k=1}^p x_{k} \beta_k = \beta_1 \]</span></p>
<p>Notice all the other <span class="math inline">\(x_2\)</span> to <span class="math inline">\(x_p\)</span> were held fixed, the interpretation of a multivariate regression coefficient is the expected change in the response per unit change in the regressor, holding all of the other regressors fixed.</p>
<p>The basic components of the linear models are exactly the same as in simple linear regression.</p>
<ul>
<li>Model <span class="math inline">\(Y_i = \sum_{k=1}^p X_{ik} \beta_{k} + \epsilon_{i}\)</span> where <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span></li>
<li>Fitted responses <span class="math inline">\(\hat Y_i = \sum_{k=1}^p X_{ik} \hat \beta_{k}\)</span></li>
<li>Residuals <span class="math inline">\(e_i = Y_i - \hat Y_i\)</span></li>
<li>Variance estimate <span class="math inline">\(\hat \sigma^2 = \frac{1}{n-p} \sum_{i=1}^n e_i ^2\)</span> (note the <span class="math inline">\(n-p\)</span> degrees of freedom)</li>
<li>To get predicted responses at new values, <span class="math inline">\(x_1, \ldots, x_p\)</span>, simply plug them into the linear model <span class="math inline">\(\sum_{k=1}^p x_{k} \hat \beta_{k}\)</span></li>
<li>Coefficients have standard errors, <span class="math inline">\(\hat \sigma_{\hat \beta_k}\)</span>, and
<span class="math inline">\(\frac{\hat \beta_k - \beta_k}{\hat \sigma_{\hat \beta_k}}\)</span>
follows a <span class="math inline">\(T\)</span> distribution with <span class="math inline">\(n-p\)</span> degrees of freedom.</li>
<li>Predicted responses have standard errors and we can calculate predicted and expected response intervals.</li>
</ul>
<p>These should all be pretty familiar because they’re basically the same as what we did for linear aggression, the difference is we have more terms now. Remember in linear aggression we had two terms, we had an intercept and a covariant now we’re just adding more covariants potentially.</p>
<p>One point to note is that the variance estimate is not quite the same as the average squared residuals. In linear regression we divided by <span class="math inline">\(n-2\)</span>, now we divide by <span class="math inline">\(n-p\)</span>. That’s kind of a technical point because if you know <span class="math inline">\(n-p\)</span> of the residuals you implicitly know the last <span class="math inline">\(p\)</span> of them due to some linear constraints. That’s a minor point you can think of the residuals variants estimate is nothing other than the average square residuals for the most part with <span class="math inline">\(N-p\)</span> part not withstanding.</p>
<p>In a sense all the things we knew about from linear regression carryover to multi-variable regression.</p>
<p>To end this section, we want to emphasize how important linear models are to the data scientist. Before you do any machine learning or any complex algorithm, linear models should be your first attempt. They offer parsimonious and well understood easily describe relationships between predictors and response. There are some modern
machine learning algorithms that can beat some of the properties of linear models, like the imposed linearity. Nonetheless, linear models should always be your starting point. There’s some amazing things you can do with linear models that you may not think that would be possible. For example, you can take a time series like a music sound or something like that, and decompose it into its harmonics. This is so-called discrete Fourier transform can be thought of the as the fit from a linear model. You can flexibly fit rather complicated functions and curves and things like that using linear models. You can fit factor variables as predictors. ANOVA and ANCOVA are special cases of linear models. You can uncover complex multivariate relationships within a response and you can build fairly accurate prediction models.</p>
</div>
</div>
<div id="multi-variable-regression-tips-and-tricks" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Multi-variable regression tips and tricks</h2>
<p>Let’s start this discussion with the famous Swiss Fertility Data. Using the following command you can load the data and see the documentation.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="week-03.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(datasets); </span>
<span id="cb125-2"><a href="week-03.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(swiss); </span>
<span id="cb125-3"><a href="week-03.html#cb125-3" aria-hidden="true" tabindex="-1"></a>?swiss</span></code></pre></div>
<p>The data shows standardized fertility measure and socio-economic indicators for each of 47 French-speaking provinces of Switzerland at about 1888. A data frame with 47 observations on 6 variables, each of which is in percent, i.e., in [0, 100]. The variables are:</p>
<ul>
<li>[,1] Fertility a common standardized fertility measure</li>
<li>[,2] Agriculture % of males involved in agriculture as occupation</li>
<li>[,3] Examination % draftees receiving highest mark on army examination</li>
<li>[,4] Education % education beyond primary school for draftees</li>
<li>[,5] Catholic % catholic (as opposed to protestant)</li>
<li>[,6] Infant.Mortality live births who live less than 1 year</li>
</ul>
<p>All variables but Fertility give proportions of the population.</p>
<p>Visualizing some of the basic scatter plots is always a good practice.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="week-03.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span></code></pre></div>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;GGally&#39;:
##   method from   
##   +.gg   ggplot2</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="week-03.html#cb129-1" aria-hidden="true" tabindex="-1"></a>g <span class="ot">&lt;-</span> <span class="fu">ggpairs</span>(</span>
<span id="cb129-2"><a href="week-03.html#cb129-2" aria-hidden="true" tabindex="-1"></a>  swiss,</span>
<span id="cb129-3"><a href="week-03.html#cb129-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">lower =</span> <span class="fu">list</span>(<span class="at">continuous =</span> <span class="st">&quot;smooth&quot;</span>),</span>
<span id="cb129-4"><a href="week-03.html#cb129-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">wrap =</span> <span class="cf">function</span>(...) {</span>
<span id="cb129-5"><a href="week-03.html#cb129-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggally_smooth</span>(..., <span class="at">method =</span> <span class="st">&quot;loess&quot;</span>)</span>
<span id="cb129-6"><a href="week-03.html#cb129-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb129-7"><a href="week-03.html#cb129-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Warning in warn_if_args_exist(list(...)): Extra arguments: &#39;wrap&#39; are being
## ignored. If these are meant to be aesthetics, submit them using the &#39;mapping&#39;
## variable within ggpairs with ggplot2::aes or ggplot2::aes_string.</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="week-03.html#cb131-1" aria-hidden="true" tabindex="-1"></a>g</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>In this plot you see fertility is on the x-axis for all the plots in the first column, agriculture is on the x-axis for all of the plots in the second column. Agriculture is also on the y-axis for the first graph. In addition, the corresponding upper triangular part of the matrix gives the correlation between the two variables. For example, fertility and agriculture the relation turns out to be fairly linear with confidence prediction band around it. The correlation between the two is 0.35.</p>
<p>Let’s investigate the relationship where agriculture, the percent of the province that works in the agricultural industry, with fertility.</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="week-03.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Fertility <span class="sc">~</span> . , <span class="at">data =</span> swiss))<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##                    Estimate  Std. Error   t value     Pr(&gt;|t|)
## (Intercept)      66.9151817 10.70603759  6.250229 1.906051e-07
## Agriculture      -0.1721140  0.07030392 -2.448142 1.872715e-02
## Examination      -0.2580082  0.25387820 -1.016268 3.154617e-01
## Education        -0.8709401  0.18302860 -4.758492 2.430605e-05
## Catholic          0.1041153  0.03525785  2.952969 5.190079e-03
## Infant.Mortality  1.0770481  0.38171965  2.821568 7.335715e-03</code></pre>
<p>Tilde period in <code>lm</code> function is a shorthand for all the other variables in the data frame. The output of the <code>summary</code> function gives the coefficients of the model. The first column gives the estimated coefficients, the second column gives the standard errors of the coefficients, the third column gives the t-statistics, and the fourth column gives the p-values. The p-values are the probability of observing a t-statistic as extreme as the one observed, if the true coefficient were 0.</p>
<p>The number <span class="math inline">\(-0.17\)</span> in the <code>Agriculture</code> variable row is interpreted as: we expect a 0.17 decrease, in standardized fertility for every 1% increase in the percentage
of males involved in agriculture, holding the other variables constant. Meaning we hold examination and education, percent Catholic and infant mortality constant.</p>
<p>The next column, the standard error 0.07, talks about how precise that coefficient is. It talks about the statistical variability of that coefficient. If we wanted to perform a hypothesis test, we would take the estimate, subtract off the hypothesized value, which in this case is zero, and divide it by the standard error of the estimate. Which is the definition of T-statistic. R conveniently provides it to us, -2.448.</p>
<p>We can calculate the probability of getting a t-statistic as extreme as that. As small as negative 2.448 or smaller, and because we’re doing a two-sided test,
we would double that p-value. The degrees of freedom are <span class="math inline">\(n - #coefficients\)</span>, including the intercept. But again, R does that on our behalf, and that works out to be 0.018. By standard thresholding rules, type one error rate of say 5%, that would be statistically significant.</p>
<p>In the following section we will see how the process of model selection changes the estimates. We start by contrasting the model with a model that just has agriculture as predictor, the previous model had all the other variables in this predictor.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="week-03.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Fertility <span class="sc">~</span> Agriculture, <span class="at">data =</span> swiss))<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##               Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) 60.3043752 4.25125562 14.185074 3.216304e-18
## Agriculture  0.1942017 0.07671176  2.531577 1.491720e-02</code></pre>
<p>The agriculture variable is about the same magnitude, 0.19 instead of 0.17 but with changed signs. Instead of agriculture having a negative effect on fertility, it has a positive effect on fertility. Adjusting for the other variables changes the actual direction of the effect of agriculture on fertility. This is the impact of something so-called Simpson’s Paradox. Notice in both cases the agriculture coefficient is strongly statistically significant.
We would like to create (via simulation) an example where an effect can reverse itself. It can help us understand Simpson’s paradox could happen.
Keep in mind, regression is a dynamic process, where you have to think about what variables to include and why. If there hasn’t been randomization to
protect you from confounding, you have to go through a scientific dynamic process of putting confounders in and out and thinking about what they’re
doing to your effective interest in order to evaluate it.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="week-03.html#cb136-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>; x2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">:</span> n; x1 <span class="ot">&lt;-</span> .<span class="dv">01</span> <span class="sc">*</span> x2 <span class="sc">+</span> <span class="fu">runif</span>(n, <span class="sc">-</span>.<span class="dv">1</span>, .<span class="dv">1</span>); y <span class="ot">=</span> <span class="sc">-</span>x1 <span class="sc">+</span> x2 <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> .<span class="dv">01</span>)</span>
<span id="cb136-2"><a href="week-03.html#cb136-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="week-03.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x1))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##              Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept)  1.541863    1.00095  1.54040 1.266858e-01
## x1          94.864140    1.69486 55.97166 3.353361e-76</code></pre>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="week-03.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##                  Estimate   Std. Error      t value      Pr(&gt;|t|)
## (Intercept)  0.0005680538 0.0022163029    0.2563069  7.982566e-01
## x1          -0.9948909569 0.0215079477  -46.2568987  6.596463e-68
## x2           0.9999279772 0.0002209948 4524.6669855 4.719142e-260</code></pre>
<p>The second regressor, <span class="math inline">\(x_2\)</span>, is the values <span class="math inline">\(1-n\)</span>, <span class="math inline">\(x_1\)</span> is a variable that depends on <span class="math inline">\(x_2\)</span> and random noise. Think of <span class="math inline">\(x_2\)</span> as something we might measure regularly, like days, and <span class="math inline">\(x_1\)</span> as something like a saving account where the balance goes up with time and random fluctuations. The random fluctuations impact the spending, so the money doesn’t necessarily always just go up. It goes up and down sporadically, but the linear trend is going up. Let’s assume y is happiness with a measure like <code>y = -x1 + x2 + noise</code>. The true generating model <code>y</code> is negatively associated with <code>-x1</code> suggesting happiness is negatively associated with money and positively associated with <code>x2</code>, so it goes up with time and down with <code>x1</code> with some random normal noise. We know from the model <code>y = -x1 + x2 + noise</code> the outcome depends negatively on <code>x1</code> with a coefficient of minus 1, and depends positively on <code>x2</code> with a coefficient of plus 1. If fit <code>x1</code> by itself we get an enormous coefficient, 95, which is clearly wrong. It’s nothing near to the negative 1 that it’s supposed to be or that we would hope it would be. It is picking up the residual effect of <code>x2</code> that’s a big driver of y, but when we fit the correct model, <code>x1</code> and <code>x2</code>, together we will get the correct coefficients, about minus 1 for <code>x1</code>, and about plus 1 for <code>x2</code>. You can imagine why this would happen by answering: what is regression doing? It’s taking <code>x1</code> and removing the linear effect of <code>x2</code>.</p>
<p>Let’s do some plots to highlight this, just to show us how it works a little bit.</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="week-03.html#cb141-1" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">y =</span> y, <span class="at">x1 =</span> x1, <span class="at">x2 =</span> x2, <span class="at">ey =</span> <span class="fu">resid</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x2)), <span class="at">ex1 =</span> <span class="fu">resid</span>(<span class="fu">lm</span>(x1 <span class="sc">~</span> x2)))</span>
<span id="cb141-2"><a href="week-03.html#cb141-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb141-3"><a href="week-03.html#cb141-3" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> <span class="fu">ggplot</span>(dat, <span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x1, <span class="at">colour =</span> x2))</span>
<span id="cb141-4"><a href="week-03.html#cb141-4" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> g <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">colour=</span><span class="st">&quot;grey50&quot;</span>, <span class="at">size =</span> <span class="dv">5</span>) <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>) </span>
<span id="cb141-5"><a href="week-03.html#cb141-5" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> g <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">4</span>) </span>
<span id="cb141-6"><a href="week-03.html#cb141-6" aria-hidden="true" tabindex="-1"></a>g</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>There is a clear positive linear relationship, between the <code>x1</code> and <code>y</code>. However, with x2, which is the color, there’s also clear positive gradient. As y goes up, so does x2. And also you can see as x1 goes up, so does x2. So you can see the confounding that’s happening here.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="week-03.html#cb143-1" aria-hidden="true" tabindex="-1"></a>g2 <span class="ot">=</span> <span class="fu">ggplot</span>(dat, <span class="fu">aes</span>(<span class="at">y =</span> ey, <span class="at">x =</span> ex1, <span class="at">colour =</span> x2))  </span>
<span id="cb143-2"><a href="week-03.html#cb143-2" aria-hidden="true" tabindex="-1"></a>g2 <span class="ot">=</span> g2 <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">colour=</span><span class="st">&quot;grey50&quot;</span>, <span class="at">size =</span> <span class="dv">5</span>) <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">4</span>) </span>
<span id="cb143-3"><a href="week-03.html#cb143-3" aria-hidden="true" tabindex="-1"></a>g2</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>If we plot the residuals you can see that for the residual y and the residual <code>x1</code>, there’s a clear negative linear relationship, and if you stare at it enough, you realize that the slope of this line should be around negative 1. You can also see that the <code>x2</code> variable is clearly not related to the residual <code>x1</code> variable.</p>
<p>It is important to remember the above explanation doesn’t mean that throwing every variable into your regression model is the right thing to do. There’s consequences to throwing in unnecessary variables. It can make your model less interpretable, it can make your model less stable, and it can make your model less generalizable. It’s important to think about what variables you’re putting in and why.</p>
<p>In the earlier example about Swiss data the agriculture effect reversed itself after we included the other variables in the model. You will find that this happens quite a bit when education and examination are included. Educational attainment is negatively correlated with the percent working in agriculture, a correlation of -0.64. In addition, education and examination are kind of measuring the same thing. Their correlation, those two variables is 0.7. The percent of males in the province working in agriculture is negatively related to educational attainment (correlation of -0.6395225) and Education and Examination (correlation of 0.6984153) are obviously measuring similar things. The question is: is the positive marginal an artifact for not having accounted for, say, Education level? (Education does have a stronger effect, by the way.)
At the minimum, anyone claiming that provinces that are more agricultural have higher fertility rates would immediately be open to criticism.</p>
<p><em>Notice</em>
What if we include an unnecessary variable?
Here we introduce <code>z</code> which adds no new linear information, since it’s a linear combination of variables already included. R just drops terms that are linear combinations of other terms.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="week-03.html#cb145-1" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> swiss<span class="sc">$</span>Agriculture <span class="sc">+</span> swiss<span class="sc">$</span>Education</span>
<span id="cb145-2"><a href="week-03.html#cb145-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Fertility <span class="sc">~</span> . <span class="sc">+</span> z, <span class="at">data =</span> swiss)</span></code></pre></div>
<pre><code>## Warning in terms.formula(formula, data = data): &#39;varlist&#39; has changed (from
## nvar=6) to new 7 after EncodeVars() -- should no longer happen!</code></pre>
<pre><code>## 
## Call:
## lm(formula = Fertility ~ . + z, data = swiss)
## 
## Coefficients:
##      (Intercept)       Agriculture       Examination         Education  
##          66.9152           -0.1721           -0.2580           -0.8709  
##         Catholic  Infant.Mortality                 z  
##           0.1041            1.0770                NA</code></pre>
<div id="dummy-variables-are-smart" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Dummy variables are smart</h3>
<p>You might be surprised to find out how flexible linear regression models are. For example, you can fit factor variables as regressors and come up with things like
analysis of variance as a special case of linear models.</p>
<p>Consider the linear model <span class="math inline">\(Y_i = \beta_0 + X_{i1} \beta_1 + \epsilon_{i}\)</span> where each <span class="math inline">\(X_{i1}\)</span> is binary so that it is a 1 if measurement <span class="math inline">\(i\)</span> is in a group and 0 otherwise. (Treated versus not in a clinical trial, for example.) The estimated mean for the treated group is the mean of the people who are treated. Then for people in the treated group we can write <span class="math inline">\(E[Y_i] = \beta_0 + \beta_1\)</span>. <span class="math inline">\(\beta_1\)</span> is interpreted as the increase, or decrease if it’s negative, in the mean response for those that were treated.
Similarly for people without treatment we have <span class="math inline">\(E[Y_i] = \beta_0\)</span>.</p>
<p>The LS fits work out to be <span class="math inline">\(\hat \beta_0 + \hat \beta_1\)</span> is the mean for those in the group and <span class="math inline">\(\hat \beta_0\)</span> is the mean for those not in the group.
You see that linear regression provides the fitted values and tell you about the means for both of the groups, in addition it gives you an inference for comparing the two groups automatically.</p>
<p><strong>Note</strong> including a binary variable that is 1 for those not in the group would be redundant. It would create three parameters to describe two means.</p>
<p>We can generalize this to more than two groups. If we have a three-level variable, we can create two binary variables, one for each level, and then we can compare the means of the three groups. For example, imagine you have some outcome but you want to compare it to U.S. political party affiliation. In this case, let’s say you were only considering those who were Democrats, Republicans, or registered Independents. Well, you can do that by having a variable X1, that’s one for Republicans and zero for otherwise, a variable X2 that’s one for Democrats and zero for otherwise, we omit the X3 for Independents because of redundancy. If we know that you’re not Republican and not a Democrat, then you must be an Independent in our data set the way we’ve set things up and having a third variable wouldn’t have any new information.
<span class="math display">\[Y_i = \beta_0 + X_{i1} \beta_1 + X_{i2} \beta_2 + \epsilon_i\]</span>
The mean for the three groups are:
* If <span class="math inline">\(i\)</span> is Republican <span class="math inline">\(E[Y_i] = \beta_0 +\beta_1\)</span>
* If <span class="math inline">\(i\)</span> is Democrat <span class="math inline">\(E[Y_i] = \beta_0 + \beta_2\)</span>.
* If <span class="math inline">\(i\)</span> is Independent <span class="math inline">\(E[Y_i] = \beta_0\)</span>.</p>
<p>If we compare the means like <span class="math inline">\(\beta_0\)</span> the mean for the Independents versus <span class="math inline">\(\beta_0 +\beta_1\)</span> the mean for the Republicans, i.e. subtract those two, we get <span class="math inline">\(\beta_1\)</span>. Which means <span class="math inline">\(\beta_1\)</span> compares Republicans to Independents, and similarly <span class="math inline">\(\beta_2\)</span> compares Democrats to Independents and <span class="math inline">\(\beta_1 - \beta_2\)</span> compares Republicans to Democrats. By omitting the regression variable for the Independents, the intercept became the value for the Independents, and all of the other coefficients have become interpreted relative to Independents and shows choice of reference category changes the interpretation. If we had included the regressor for
Independents and excluded the one for Republicans, then the intercept would be for Republicans, and the coefficient in front of the Democratic would be Democrats versus Republicans. The coefficient in front of the Independent would be Independent versus Republican. To illustrate how this works we move to R.
In this example we look at a factor variable and see how R is treating it the dataset is <code>InsectSprays</code> and we’re going to fit a linear model to it.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="week-03.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(datasets);<span class="fu">data</span>(InsectSprays); <span class="fu">require</span>(stats); <span class="fu">require</span>(ggplot2)</span>
<span id="cb148-2"><a href="week-03.html#cb148-2" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">data =</span> InsectSprays, <span class="fu">aes</span>(<span class="at">y =</span> count, <span class="at">x =</span> spray, <span class="at">fill  =</span> spray))</span>
<span id="cb148-3"><a href="week-03.html#cb148-3" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> g <span class="sc">+</span> <span class="fu">geom_violin</span>(<span class="at">colour =</span> <span class="st">&quot;black&quot;</span>, <span class="at">size =</span> <span class="dv">2</span>)</span>
<span id="cb148-4"><a href="week-03.html#cb148-4" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> g <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Type of spray&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Insect count&quot;</span>)</span>
<span id="cb148-5"><a href="week-03.html#cb148-5" aria-hidden="true" tabindex="-1"></a>g</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p><code>Y</code> is the count, the number of insects, <code>X</code> is the spray. We use a violin plot to show the data, which is kind of like a histogram but sort of tilted on its side and repeated on both sides so it looks a little like a violin. It looks like a violin if you’re data cooperates, otherwise, it looks like a blob. As you can see there are eight spray A, B, C, D, E, and F and you can see the insect counts. It’s unfortunate they’re not telling us whether or not the count is the count of
the number of alive or the number dead insects. So we don’t know if this is a better spray or a worse spray. However, we still can test the difference between different factor levels in this case using linear models. Wwhen we include insect spray as a linear model and y as an outcome.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="week-03.html#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(count <span class="sc">~</span> spray, <span class="at">data =</span> InsectSprays))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##                Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept)  14.5000000   1.132156 12.8074279 1.470512e-19
## sprayB        0.8333333   1.601110  0.5204724 6.044761e-01
## sprayC      -12.4166667   1.601110 -7.7550382 7.266893e-11
## sprayD       -9.5833333   1.601110 -5.9854322 9.816910e-08
## sprayE      -11.0000000   1.601110 -6.8702352 2.753922e-09
## sprayF        2.1666667   1.601110  1.3532281 1.805998e-01</code></pre>
<p>We get the Intercept, spray B, spray C, spray D, spray E, and spray F, notice that spray A is conspicuously missing. The idea is that everything here is in comparison with spray A. So, 0.833 is the change in the mean between spray B and spray A. In this case, 14.5 is the mean for spray A. You can double check that by looking at the plot. Spray B seems reasonable affected by a little bit from spray A, whereas spray C looks like it’s affected a lot it has a coefficient of <span class="math inline">\(-12\)</span>.
If we wanted to compare spray B and spray C we would have to look at <span class="math inline">\(0.833 - (-12.416)\)</span>. We wouldn’t have a standard error for that comparison immediately. However, that would give us the estimate.</p>
<p>If we were to take the average count for the sprays, for those with spray A, we would get 14.5 with spray B we would get <span class="math inline">\(14.5 + 0.833\)</span>.
What R does is it picks the spray level that’s the lowest alphanumerically, in this case, spray level A, to set as the reference level. Here we like to show you how you can hard code the same model and not rely on R to pick the reference level.</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="week-03.html#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(count <span class="sc">~</span> </span>
<span id="cb151-2"><a href="week-03.html#cb151-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;B&#39;</span>)) <span class="sc">+</span> <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;C&#39;</span>)) <span class="sc">+</span> </span>
<span id="cb151-3"><a href="week-03.html#cb151-3" aria-hidden="true" tabindex="-1"></a>             <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;D&#39;</span>)) <span class="sc">+</span> <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;E&#39;</span>)) <span class="sc">+</span></span>
<span id="cb151-4"><a href="week-03.html#cb151-4" aria-hidden="true" tabindex="-1"></a>             <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;F&#39;</span>))</span>
<span id="cb151-5"><a href="week-03.html#cb151-5" aria-hidden="true" tabindex="-1"></a>           , <span class="at">data =</span> InsectSprays))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##                          Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept)            14.5000000   1.132156 12.8074279 1.470512e-19
## I(1 * (spray == &quot;B&quot;))   0.8333333   1.601110  0.5204724 6.044761e-01
## I(1 * (spray == &quot;C&quot;)) -12.4166667   1.601110 -7.7550382 7.266893e-11
## I(1 * (spray == &quot;D&quot;))  -9.5833333   1.601110 -5.9854322 9.816910e-08
## I(1 * (spray == &quot;E&quot;)) -11.0000000   1.601110 -6.8702352 2.753922e-09
## I(1 * (spray == &quot;F&quot;))   2.1666667   1.601110  1.3532281 1.805998e-01</code></pre>
<p>Here <code>count</code> is the outcome and we create a variable using the <code>I</code> function which performs the operation inside the regression, inside the model statement. We look at the instances where the spray is equal to B then multiply that by 1 to change it from Boolean to numeric and do the same for the other sprays and add them all together. In this example we included all of the sprays except A which means we forced A to be the reference level. The result is identical to R picking the reference level as we expected.</p>
<p>What happens if we include spray A?</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="week-03.html#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(count <span class="sc">~</span> </span>
<span id="cb153-2"><a href="week-03.html#cb153-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;B&#39;</span>)) <span class="sc">+</span> <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;C&#39;</span>)) <span class="sc">+</span>  </span>
<span id="cb153-3"><a href="week-03.html#cb153-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;D&#39;</span>)) <span class="sc">+</span> <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;E&#39;</span>)) <span class="sc">+</span></span>
<span id="cb153-4"><a href="week-03.html#cb153-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;F&#39;</span>)) <span class="sc">+</span> <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">*</span> (spray <span class="sc">==</span> <span class="st">&#39;A&#39;</span>)), <span class="at">data =</span> InsectSprays))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##                          Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept)            14.5000000   1.132156 12.8074279 1.470512e-19
## I(1 * (spray == &quot;B&quot;))   0.8333333   1.601110  0.5204724 6.044761e-01
## I(1 * (spray == &quot;C&quot;)) -12.4166667   1.601110 -7.7550382 7.266893e-11
## I(1 * (spray == &quot;D&quot;))  -9.5833333   1.601110 -5.9854322 9.816910e-08
## I(1 * (spray == &quot;E&quot;)) -11.0000000   1.601110 -6.8702352 2.753922e-09
## I(1 * (spray == &quot;F&quot;))   2.1666667   1.601110  1.3532281 1.805998e-01</code></pre>
<p>Notice it gives an NA in front of the spray A coefficient. We have six means, for six sprays and seven parameters in intercept.</p>
<p>If we do want the coefficients, instead of being interpreted as levels referenced to a control level be the mean for each of the groups? Well, we can do that by removing the intercept.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="week-03.html#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(count <span class="sc">~</span> spray <span class="sc">-</span> <span class="dv">1</span>, <span class="at">data =</span> InsectSprays))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##         Estimate Std. Error   t value     Pr(&gt;|t|)
## sprayA 14.500000   1.132156 12.807428 1.470512e-19
## sprayB 15.333333   1.132156 13.543487 1.001994e-20
## sprayC  2.083333   1.132156  1.840148 7.024334e-02
## sprayD  4.916667   1.132156  4.342749 4.953047e-05
## sprayE  3.500000   1.132156  3.091448 2.916794e-03
## sprayF 16.666667   1.132156 14.721181 1.573471e-22</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="week-03.html#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="week-03.html#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summarise</span>(<span class="fu">group_by</span>(InsectSprays, spray), <span class="at">mn =</span> <span class="fu">mean</span>(count))</span></code></pre></div>
<pre><code>## # A tibble: 6 × 2
##   spray    mn
##   &lt;fct&gt; &lt;dbl&gt;
## 1 A     14.5 
## 2 B     15.3 
## 3 C      2.08
## 4 D      4.92
## 5 E      3.5 
## 6 F     16.7</code></pre>
<p>Here <code>count</code> is the outcome and spray is the predictor, but we remove the intercept.
Notice we get a different set of coefficients, one for each spray level. It includes A, B, C, D, E and F without dropping any levels. It can do that because it has six parameters, and six means to work with. The coefficients are exactly equal to the means for each spray in the data. If calculated the means for each spray it would work out to be the same numbers.</p>
<p>We want to emphasize this model is no different than the previous model that included an intercept, and just the coefficients have a different interpretation. If we add these together, 14.5 and 0.833 from the model with intercept we should get the mean for spray B, which is the case. In the model with the intercept, the intercept is interpreted as the spray A mean and all the coefficients are interpreted as relative to spray A differences from spray A and when we fit the data without the intercept we get the mean for each spray.
The p values are testing whether or not, A is different from B, and A is different from C, and A is different from D, and so on, whereas the p values from
the model without intercept are testing whether or not those means are different from 0, which is a very different test. We were trying to illustrate how you play around with factor variables in <code>lm</code> is very important in terms of how you interpret it. It’s not just a conceptual or theoretical thing to worry about it is a very practical thing. What your intercept means changes dramatically depending on what your reference level is.</p>
<p>One more thing that we want to discuss is the idea of re-leveling. You can re-level to have differenct reference level. For example, if you want to compare spray C to spray A, you can re-level the spray variable to have C as the reference level.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="week-03.html#cb163-1" aria-hidden="true" tabindex="-1"></a>spray2 <span class="ot">&lt;-</span> <span class="fu">relevel</span>(InsectSprays<span class="sc">$</span>spray, <span class="st">&quot;C&quot;</span>)</span>
<span id="cb163-2"><a href="week-03.html#cb163-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(count <span class="sc">~</span> spray2, <span class="at">data =</span> InsectSprays))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##              Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept)  2.083333   1.132156 1.840148 7.024334e-02
## spray2A     12.416667   1.601110 7.755038 7.266893e-11
## spray2B     13.250000   1.601110 8.275511 8.509776e-12
## spray2D      2.833333   1.601110 1.769606 8.141205e-02
## spray2E      1.416667   1.601110 0.884803 3.794750e-01
## spray2F     14.583333   1.601110 9.108266 2.794343e-13</code></pre>
</div>
<div id="summary-of-the-insectsprays-example" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Summary of the InsectSprays example</h3>
<ul>
<li>If we treat Spray as a factor, R includes an intercept and omits the alphabetically first level of the factor.
<ul>
<li>All t-tests are for comparisons of Sprays versus Spray A.</li>
<li>Empirical mean for A is the intercept.</li>
<li>Other group means are the itc plus their coefficient.</li>
</ul></li>
<li>If we omit an intercept, then it includes terms for all levels of the factor.
<ul>
<li>Group means are the coefficients.</li>
<li>Tests are tests of whether the groups are different than zero. (Are the expected counts zero for that spray.)</li>
</ul></li>
<li>If we want comparisons between, Spray B and C, say we could refit the model with C (or B) as the reference level.</li>
</ul>
<p><strong>Note</strong> We want to make a few points about the InsectSprays dataset, which we believe is important for the data scientist.</p>
<ul>
<li>Counts are bounded from below by 0, violates the assumption of normality of the errors.
<ul>
<li>Also there are counts near zero, so both the actual assumption and the intent of the assumption are violated.</li>
</ul></li>
<li>Variance does not appear to be constant.</li>
<li>Perhaps taking logs of the counts would help.
<ul>
<li>There are 0 counts, so maybe log(Count + 1)</li>
</ul></li>
<li>Also, we’ll cover Poisson GLMs for fitting count data.</li>
</ul>
<p>In this section we go through an example that underlies the topic of so called ANCOVA. In this example we will fit multiple lines with different intercepts and different slopes. We will use the swiss dataset, recall we’re trying to model fertilities as a linear function of agriculture, which is the percent of that province that was working in agriculture.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="week-03.html#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(datasets); <span class="fu">data</span>(swiss)</span>
<span id="cb165-2"><a href="week-03.html#cb165-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(swiss)</span></code></pre></div>
<pre><code>##              Fertility Agriculture Examination Education Catholic
## Courtelary        80.2        17.0          15        12     9.96
## Delemont          83.1        45.1           6         9    84.84
## Franches-Mnt      92.5        39.7           5         5    93.40
## Moutier           85.8        36.5          12         7    33.77
## Neuveville        76.9        43.5          17        15     5.16
## Porrentruy        76.1        35.3           9         7    90.57
##              Infant.Mortality
## Courtelary               22.2
## Delemont                 22.2
## Franches-Mnt             20.2
## Moutier                  20.3
## Neuveville               20.6
## Porrentruy               26.6</code></pre>
<p>If we do <code>hist(swiss$Catholic)</code>, notice that it’s very bimodal, that’s because most provinces are either majority Catholic or majority Protestant, from this time period.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="week-03.html#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(swiss<span class="sc">$</span>Catholic)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>We now create a catholic, binary variable, which is one if the province is majority catholic, and zero if it’s majority protestant.</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="week-03.html#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr); </span>
<span id="cb168-2"><a href="week-03.html#cb168-2" aria-hidden="true" tabindex="-1"></a>swiss <span class="ot">=</span> <span class="fu">mutate</span>(swiss, <span class="at">CatholicBin =</span> <span class="dv">1</span> <span class="sc">*</span> (Catholic <span class="sc">&gt;</span> <span class="dv">50</span>))</span></code></pre></div>
<p>We can plot the data to see the two groups, the <code>CatholicBin</code> factor variable, that’s zero for majority Protestant and one for majority Catholic.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="week-03.html#cb169-1" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> <span class="fu">ggplot</span>(swiss, <span class="fu">aes</span>(<span class="at">x =</span> Agriculture, <span class="at">y =</span> Fertility, <span class="at">colour =</span> <span class="fu">factor</span>(CatholicBin)))</span>
<span id="cb169-2"><a href="week-03.html#cb169-2" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> g <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">6</span>, <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">4</span>)</span>
<span id="cb169-3"><a href="week-03.html#cb169-3" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> g <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;% in Agriculture&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Fertility&quot;</span>)</span>
<span id="cb169-4"><a href="week-03.html#cb169-4" aria-hidden="true" tabindex="-1"></a>g</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>For the time being, we will ignore the outlaiers and simply work on fitting a line where we want two separate lines. One for the majority Catholic provinces, and one for the majority Protestant provinces. For notations <code>Y</code> is fertility, <code>X1</code> is the percent of the province working in agriculture, and <code>X2</code> is a binary variable, where it is one if the province is over 50% catholic, and zero if the province is majority Protestant. Let’s consider model one, where we modeled the expected y, given x1 and x2, is an intercept plus a slope times x1. <span class="math inline">\(E[Y | X_1 = x_1, X_2 = 0] = \beta_0 + \beta_1 x_1\)</span>. This is the line that would disregard the religion of the province entirely. Let’s consider a second model <span class="math inline">\(E[Y | X_1 = x_1, X_2 = 1] = \beta_0 + \beta_1 x_1 + \beta_2 x_2\)</span>.
In the event that X two is equal to zero, i.e. if the province is majority protestant, this works out to be <span class="math inline">\(\beta_0 + \beta_1 x_1\)</span>. In the event that x2 is equal to one, i.e. if the province is majority Catholic, this works out to be <span class="math inline">\(\beta_0 + \beta_2 + \beta_1 x_1\)</span>.</p>
<p>The model that includes X1 and X2, but no interaction fits two models that have the same slope, but they have different intercepts, <span class="math inline">\(\beta_0\)</span> and then <span class="math inline">\(\beta_0+\beta_2\)</span>. If we consider one third model <span class="math inline">\(E[Y | X_1 = x_1, X_2 = 1] = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2\)</span>, in this model when X2 is zero, it works out to be <span class="math inline">\(\beta_0 + \beta_1 x_1\)</span>, and when X2 is 1, which is the case when the province is majority Catholic, we get <span class="math inline">\(\beta_0 + \beta_2 + \beta_1 x_1 + \beta_3 x_1\)</span>, now let’s reorganize terms to get <span class="math inline">\(\beta_0 + \beta_2 + (\beta_1 + \beta_3) x_1\)</span>.</p>
<p>This model is showing if we omitted that interaction term, we fit two lines the same slope, if we include the interaction term, we get two lines different slopes and different intercepts. And the coefficient in front of the Catholic term is going to change in the intercept going from Protestant to Catholic.</p>
</div>
<div id="exploring-the-models-in-r" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Exploring the models in R</h3>
<p>We start by fitting the model, where we fit the expected fertility as a linear function of the percent of the province working in agriculture.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="week-03.html#cb170-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Fertility <span class="sc">~</span> Agriculture, <span class="at">data =</span> swiss)</span>
<span id="cb170-2"><a href="week-03.html#cb170-2" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">=</span> g</span>
<span id="cb170-3"><a href="week-03.html#cb170-3" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">=</span> g1 <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">coef</span>(fit)[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">size =</span> <span class="dv">2</span>)</span>
<span id="cb170-4"><a href="week-03.html#cb170-4" aria-hidden="true" tabindex="-1"></a>g1</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Here we want to save the plot in <code>g1</code>, then we can keep adding different things to it. The coefficients summaries can be obtained by <code>summary(fit)$coef</code>.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="week-03.html#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Fertility <span class="sc">~</span> Agriculture <span class="sc">+</span> <span class="fu">factor</span>(CatholicBin), <span class="at">data =</span> swiss))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##                        Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)          60.8322366  4.1058630 14.815944 1.032493e-18
## Agriculture           0.1241776  0.0810977  1.531210 1.328763e-01
## factor(CatholicBin)1  7.8843292  3.7483622  2.103406 4.118221e-02</code></pre>
<p>This just disregards the color of the points. Let’s do one that fits two parallel lines.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="week-03.html#cb173-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Fertility <span class="sc">~</span> Agriculture <span class="sc">+</span> <span class="fu">factor</span>(CatholicBin), <span class="at">data =</span> swiss)</span>
<span id="cb173-2"><a href="week-03.html#cb173-2" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">=</span> g</span>
<span id="cb173-3"><a href="week-03.html#cb173-3" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">=</span> g1 <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">coef</span>(fit)[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">size =</span> <span class="dv">2</span>)</span>
<span id="cb173-4"><a href="week-03.html#cb173-4" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">=</span> g1 <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">coef</span>(fit)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">3</span>], <span class="at">slope =</span> <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">size =</span> <span class="dv">2</span>)</span>
<span id="cb173-5"><a href="week-03.html#cb173-5" aria-hidden="true" tabindex="-1"></a>g1</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Because the variable <code>CatholicBin</code> is 0 or 1, we don’t actually have to have the factor statement. Because coding a variable of 0 versus 1 treats it as a factor. However we like to call factor variables and the reason is sometimes you have a variable like 0,1,2 for a 3 level variable, and if you don’t call that a factor, R is going to treat that as a continuous regressor. It’s going to say 2 is twice 1, even if 2 is just a numeric coding for representing red hair color and 1 is for brown hair color, where 2 really has nothing to do with being twice 1 in that case.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="week-03.html#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Fertility <span class="sc">~</span> Agriculture <span class="sc">*</span> <span class="fu">factor</span>(CatholicBin), <span class="at">data =</span> swiss))<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##                                     Estimate  Std. Error    t value
## (Intercept)                      62.04993019  4.78915566 12.9563402
## Agriculture                       0.09611572  0.09881204  0.9727127
## factor(CatholicBin)1              2.85770359 10.62644275  0.2689238
## Agriculture:factor(CatholicBin)1  0.08913512  0.17610660  0.5061430
##                                      Pr(&gt;|t|)
## (Intercept)                      1.919379e-16
## Agriculture                      3.361364e-01
## factor(CatholicBin)1             7.892745e-01
## Agriculture:factor(CatholicBin)1 6.153416e-01</code></pre>
<p>We have an intercept and a slope, this intercept is the intercept for mostly Protestant provinces, the slope is the slope for mostly Protestant provinces. This 2.86 plus 62.04 is the intercept for the mostly Catholic provinces and the slope 0.096 + 0.089 is the slope for the mostly Catholic provinces. For lines with different intercepts and different slopes depending on the percent of the province that is Catholic, put an asterisk and do the fit. What happens when you add an asterisks in between two variables in R? It automatically fits the interaction. In general you want to include the main effects, if you include the interaction.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="week-03.html#cb176-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Fertility <span class="sc">~</span> Agriculture <span class="sc">*</span> <span class="fu">factor</span>(CatholicBin), <span class="at">data =</span> swiss)</span>
<span id="cb176-2"><a href="week-03.html#cb176-2" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">=</span> g</span>
<span id="cb176-3"><a href="week-03.html#cb176-3" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">=</span> g1 <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">coef</span>(fit)[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">size =</span> <span class="dv">2</span>)</span>
<span id="cb176-4"><a href="week-03.html#cb176-4" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">=</span> g1 <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">coef</span>(fit)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">3</span>], </span>
<span id="cb176-5"><a href="week-03.html#cb176-5" aria-hidden="true" tabindex="-1"></a>                          <span class="at">slope =</span> <span class="fu">coef</span>(fit)[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">4</span>], <span class="at">size =</span> <span class="dv">2</span>)</span>
<span id="cb176-6"><a href="week-03.html#cb176-6" aria-hidden="true" tabindex="-1"></a>g1</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-25-1.png" width="672" />
based on the coefficients all the Catholic terms were positive the line with the slightly higher intercept is the Catholic line and the line for the slightly lower
intercept is the mostly Protestant. Now you can probably see that well for the blue dots it is not clear how the two outlier blue dots impacting the fit, so we might want to investigate that. We will do that in the next section where we talk about residuals and influence diagnostics and that sort of thing.</p>
</div>
</div>
<div id="adjustment" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Adjustment</h2>
<p>Adjustment, is the idea of putting regressors into a linear model to investigate the role of a third variable on the relationship between another two. Since it is often the case that a third variable can distort, or confound if you will, the relationship between two others.</p>
<p>As an example, consider looking at lung cancer rates and breath mint usage. For the sake of completeness, imagine if you were looking at forced expiratory volume (a measure of lung function) and breath mint usage. If you found a statistically significant regression relationship, it wouldn’t be wise to rush off to the newspapers with the headline “Breath mint usage causes shortness of breath!”, for a variety of reasons. First off, even if the association is sound, you don’t know that it’s causal. But, more importantly in this case, the likely culprit is smoking habits. Smoking rates are likely related to both breath mint usage rates and lung function. How would you defend your finding against the accusation that it’s just variability in smoking habits?</p>
<p>If your finding held up among non-smokers and smokers analyzed separately, then you might have something. In other words, people wouldn’t even begin to believe this finding unless it held up while holding smoking status constant. That is the idea of adding a regression variable into a model as adjustment. The coefficient of interest is interpreted as the effect of the predictor on the response, holding the adjustment variable constant.</p>
<p>In this lecture, we’ll use simulation to investigate how adding a regressor into a model addresses the idea of adjustment.</p>
<div id="adjustment-examples" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Adjustment Examples</h3>
<p>In this section, we’re gonna go over some examples of how adjusting for one variable can impact the apparent relationship of another variable on an outcome. The easiest way to see this is to look at a two group variable. For example, a treatment versus a control or something you might see in an AB test when we’re adjusting for a continuous variable. Here’s the first simulation:</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="week-03.html#cb177-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>; t <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="fu">c</span>(n<span class="sc">/</span><span class="dv">2</span>, n<span class="sc">/</span><span class="dv">2</span>)); x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>), <span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>));</span>
<span id="cb177-2"><a href="week-03.html#cb177-2" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="dv">0</span>; beta1 <span class="ot">&lt;-</span> <span class="dv">2</span>; tau <span class="ot">&lt;-</span> <span class="dv">1</span>; sigma <span class="ot">&lt;-</span> .<span class="dv">2</span></span>
<span id="cb177-3"><a href="week-03.html#cb177-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> x <span class="sc">*</span> beta1 <span class="sc">+</span> t <span class="sc">*</span> tau <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> sigma)</span>
<span id="cb177-4"><a href="week-03.html#cb177-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>)</span>
<span id="cb177-5"><a href="week-03.html#cb177-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb177-6"><a href="week-03.html#cb177-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb177-7"><a href="week-03.html#cb177-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb177-8"><a href="week-03.html#cb177-8" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> t)</span>
<span id="cb177-9"><a href="week-03.html#cb177-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb177-10"><a href="week-03.html#cb177-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">3</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb177-11"><a href="week-03.html#cb177-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb177-12"><a href="week-03.html#cb177-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;salmon&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>In this case, the red group was the group reciving treatment and the blue group was control. The horizontal lines show the marginal effect of group status disregarding the x. The y was a measure of blood pressure, then we would think that if we hadn’t factored in x, the mean for the group that received the treatment was around 2 and the mean for the control was around 0.8. You notice there’s a pretty clear linear relationship between the outcome and the regressor. So what we could do is fit a model that looks like <span class="math inline">\(y = \beta_0 + \beta_1 T + \beta_2 x + \epsilon\)</span>, where <span class="math inline">\(T\)</span> is the treatment indicator, with values of <span class="math inline">\(\{0,1\}\)</span>. This would fit two parallel lines with <span class="math inline">\(\beta_1\)</span> representing the change in intercepts between the groups and <span class="math inline">\(\beta_2\)</span> the common slope that exists across the two groups.
<img src="resources/images/Week03_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Taking a closer look at y-axis shows the marginal effect, the effect that we have if we disregard x, and the effect that we have if we incorporate x in a linear model and look at the change in the intercepts, are about the same. In addition, note in this example there is a lot of direct evidence to compare the groups for
any given value of x. If we binned x we would have red and blue circles for a direct comparison of the treatment for kind of a fairly isolated level of x.</p>
<p>Let’s try a setting where it’s gonna make a big difference.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="week-03.html#cb178-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>; t <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="fu">c</span>(n<span class="sc">/</span><span class="dv">2</span>, n<span class="sc">/</span><span class="dv">2</span>)); x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>), <span class="fl">1.5</span> <span class="sc">+</span> <span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>));</span>
<span id="cb178-2"><a href="week-03.html#cb178-2" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="dv">0</span>; beta1 <span class="ot">&lt;-</span> <span class="dv">2</span>; tau <span class="ot">&lt;-</span> <span class="dv">0</span>; sigma <span class="ot">&lt;-</span> .<span class="dv">2</span></span>
<span id="cb178-3"><a href="week-03.html#cb178-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> x <span class="sc">*</span> beta1 <span class="sc">+</span> t <span class="sc">*</span> tau <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> sigma)</span>
<span id="cb178-4"><a href="week-03.html#cb178-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>)</span>
<span id="cb178-5"><a href="week-03.html#cb178-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb178-6"><a href="week-03.html#cb178-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb178-7"><a href="week-03.html#cb178-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb178-8"><a href="week-03.html#cb178-8" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> t)</span>
<span id="cb178-9"><a href="week-03.html#cb178-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb178-10"><a href="week-03.html#cb178-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">3</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb178-11"><a href="week-03.html#cb178-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb178-12"><a href="week-03.html#cb178-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;salmon&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>The horizontal lines show marginal difference between the red, treated group, and the blue, control group. However, if we fit that model and look at the change in the intercepts, we’d see a tiny difference. This is a case where we would go from a massive treatment effect to nothing when we accounted for x. Moreover, if we knew that the x value was one or smaller, we know that value is in the blue group, and if it was 1.5 or higher, we know the value was in the treated group. So knowledge of x at some level pretty much gives us perfect knowledge of received treatment. In a randomized setuation it would be very hard to pick what treatment you had based on your x level because the x levels were all jumbled up some of the high x levels went to the treated, some of the high x levels went to the control. However, in this case, we clearly didn’t randomize. The question of which model here is the right one to consider is not the discussion for this section, here we want to show how the inclusion of x can change the estimate.
As an example, imagin y, your outcome, was the blood pressure and the x variable was cholesterol or something highly related to whether or not you would’ve gotten prescribed a medication. You could see that adjusting for x is really just adjusting for the same thing that would lead you to have treatment. Again, this is what makes observational data analysis very hard as opposed to instances where you have randomized sample. This is an example where we had a strong marginal effect when we disregarded x, and a very subtle or a non-existent effect when we accounted for x. One more point is there is no value of x we can hold constant and compare red versus blue directly, which is a bad setting, where we’re relying very heavily on the model to compare the group.</p>
<p>A summary of the important points about the previous example can be listed as:
* The X variable is highly related to group status
* The X variable is related to Y, the intercept doesn’t depend on the group variable.
* The X variable remains related to Y holding group status constant
* The group variable is marginally related to Y disregarding X.
* The model would estimate no adjusted effect due to group.
* There isn’t any data to inform the relationship between group and Y.
* This conclusion is entirely based on the model.</p>
<p>Another senario is where there is some overlap between data point.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="week-03.html#cb179-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>; t <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="fu">c</span>(n<span class="sc">/</span><span class="dv">2</span>, n<span class="sc">/</span><span class="dv">2</span>)); x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>), .<span class="dv">9</span> <span class="sc">+</span> <span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>));</span>
<span id="cb179-2"><a href="week-03.html#cb179-2" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="dv">0</span>; beta1 <span class="ot">&lt;-</span> <span class="dv">2</span>; tau <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span>; sigma <span class="ot">&lt;-</span> .<span class="dv">2</span></span>
<span id="cb179-3"><a href="week-03.html#cb179-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> x <span class="sc">*</span> beta1 <span class="sc">+</span> t <span class="sc">*</span> tau <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> sigma)</span>
<span id="cb179-4"><a href="week-03.html#cb179-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>)</span>
<span id="cb179-5"><a href="week-03.html#cb179-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb179-6"><a href="week-03.html#cb179-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb179-7"><a href="week-03.html#cb179-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb179-8"><a href="week-03.html#cb179-8" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> t)</span>
<span id="cb179-9"><a href="week-03.html#cb179-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb179-10"><a href="week-03.html#cb179-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">3</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb179-11"><a href="week-03.html#cb179-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb179-12"><a href="week-03.html#cb179-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;salmon&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>There is some direct evidence for comparing the two groups. The marginal mean for the red and blue groups suggests the red is higher than the blue. However, the linear fit in the intercepts shows the blue is higher than the red. This shows the adjusted estimate is significant and the exact opposite of the unadjusted estimate. This phenomenon is often called Simpson’s Paradox, and the idea is things can change to the exact opposite when you perform adjustment.</p>
<p>Next senario is shown in the following plot.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="week-03.html#cb180-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>; t <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="fu">c</span>(n<span class="sc">/</span><span class="dv">2</span>, n<span class="sc">/</span><span class="dv">2</span>)); x <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">5</span> <span class="sc">+</span> <span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>), <span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>));</span>
<span id="cb180-2"><a href="week-03.html#cb180-2" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="dv">0</span>; beta1 <span class="ot">&lt;-</span> <span class="dv">2</span>; tau <span class="ot">&lt;-</span> <span class="dv">1</span>; sigma <span class="ot">&lt;-</span> .<span class="dv">2</span></span>
<span id="cb180-3"><a href="week-03.html#cb180-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> x <span class="sc">*</span> beta1 <span class="sc">+</span> t <span class="sc">*</span> tau <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> sigma)</span>
<span id="cb180-4"><a href="week-03.html#cb180-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>)</span>
<span id="cb180-5"><a href="week-03.html#cb180-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb180-6"><a href="week-03.html#cb180-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb180-7"><a href="week-03.html#cb180-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb180-8"><a href="week-03.html#cb180-8" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> t)</span>
<span id="cb180-9"><a href="week-03.html#cb180-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb180-10"><a href="week-03.html#cb180-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">3</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb180-11"><a href="week-03.html#cb180-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb180-12"><a href="week-03.html#cb180-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;salmon&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>Here there is no marginal effect. However, there’s a huge effect when we adjust for x. There’s no simple rule that says this is always what will happen with adjustment. Pretty much any permutation of going from significant to non-significant, staying both significant, staying non-significant, flipping signs can occur.</p>
<p>As our final example we look at the following graph.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="week-03.html#cb181-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>; t <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="fu">c</span>(n<span class="sc">/</span><span class="dv">2</span>, n<span class="sc">/</span><span class="dv">2</span>)); x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="fu">runif</span>(n<span class="sc">/</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>));</span>
<span id="cb181-2"><a href="week-03.html#cb181-2" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="dv">0</span>; beta1 <span class="ot">&lt;-</span> <span class="dv">2</span>; tau <span class="ot">&lt;-</span> <span class="dv">0</span>; tau1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">4</span>; sigma <span class="ot">&lt;-</span> .<span class="dv">2</span></span>
<span id="cb181-3"><a href="week-03.html#cb181-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> x <span class="sc">*</span> beta1 <span class="sc">+</span> t <span class="sc">*</span> tau <span class="sc">+</span> t <span class="sc">*</span> x <span class="sc">*</span> tau1 <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> sigma)</span>
<span id="cb181-4"><a href="week-03.html#cb181-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>)</span>
<span id="cb181-5"><a href="week-03.html#cb181-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb181-6"><a href="week-03.html#cb181-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb181-7"><a href="week-03.html#cb181-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">mean</span>(y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n]), <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb181-8"><a href="week-03.html#cb181-8" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> t <span class="sc">+</span> <span class="fu">I</span>(x <span class="sc">*</span> t))</span>
<span id="cb181-9"><a href="week-03.html#cb181-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb181-10"><a href="week-03.html#cb181-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(fit)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">3</span>], <span class="fu">coef</span>(fit)[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">coef</span>(fit)[<span class="dv">4</span>], <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb181-11"><a href="week-03.html#cb181-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], y[<span class="dv">1</span> <span class="sc">:</span> (n<span class="sc">/</span><span class="dv">2</span>)], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb181-12"><a href="week-03.html#cb181-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], y[(n<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">:</span> n], <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;salmon&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>This example considers an instance where assuming the slopes were common across the two groups would be wrong. The linear model <span class="math inline">\(y = \beta_0 + \beta_1 T + \beta_2 x + \beta_3 T x + \epsilon\)</span> would fit two lines with different intercepts and different slopes. Another important thing to ascertain is there is no treatment effect.</p>
<p>If we look at the center there is no evidence of a treatment effect, if we look at the right side of the graph there is a big evidence that blue has a higher outcome than red, and if you look at the left side we see there is a lot of evidence that red has a higher outcome than blue. The interaction is the reason why the main treatment effect doesn’t have a lot of meaning and the coefficient in front of the treated effects is not interpreted as the treatment effect by itself. The treatment effect depends on what level of x you’re at, and you can’t just read the term from the regression output associated with the treatment and act as if it’s a treatment effect because we have an interaction term in the model. Again this shows how adjustment can really change things if you have a setting where you have not just adjustment, but so-called modification.</p>
<p>We want to reiterate that nothing we’ve talked about is specific to having a binary treatment and a continuous x.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="week-03.html#cb182-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb182-2"><a href="week-03.html#cb182-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>; x2 <span class="ot">&lt;-</span> <span class="fu">runif</span>(n); x1 <span class="ot">&lt;-</span> p <span class="sc">*</span> <span class="fu">runif</span>(n) <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">*</span> x2</span>
<span id="cb182-3"><a href="week-03.html#cb182-3" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="dv">0</span>; beta1 <span class="ot">&lt;-</span> <span class="dv">1</span>; tau <span class="ot">&lt;-</span> <span class="dv">4</span> ; sigma <span class="ot">&lt;-</span> .<span class="dv">01</span></span>
<span id="cb182-4"><a href="week-03.html#cb182-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> x1 <span class="sc">*</span> beta1 <span class="sc">+</span> tau <span class="sc">*</span> x2 <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> sigma)</span>
<span id="cb182-5"><a href="week-03.html#cb182-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1, y, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>)</span>
<span id="cb182-6"><a href="week-03.html#cb182-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x1), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb182-7"><a href="week-03.html#cb182-7" aria-hidden="true" tabindex="-1"></a>co.pal <span class="ot">&lt;-</span> <span class="fu">heat.colors</span>(n)</span>
<span id="cb182-8"><a href="week-03.html#cb182-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x1, y, <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> co.pal[<span class="fu">round</span>((n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> x2 <span class="sc">+</span> <span class="dv">1</span>)], <span class="at">cex =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>The above plot shows outcome, y, and the continuous variable <span class="math inline">\(x1\)</span> and continuous variable <span class="math inline">\(x2\)</span> color coded, higher lighter values mean higher, and more red darker values means lower. At first glance you might say there is not much of a relationship between y and x1, however, if we look at it in three dimensions you can see that most of the variation of y is explained by its relationship with x2. Here we show the 2D plot of y versus x2.
<img src="resources/images/Week03_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>An easy way to look at the other variables effect without having to resort to three dimensional plots, which don’t work if you move beyond two variables is to look at residuals.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="week-03.html#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(<span class="fu">lm</span>(x1 <span class="sc">~</span> x2)), <span class="fu">resid</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x2)), <span class="at">frame =</span> <span class="cn">FALSE</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">bg =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">pch =</span> <span class="dv">21</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb183-2"><a href="week-03.html#cb183-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(<span class="fu">I</span>(<span class="fu">resid</span>(<span class="fu">lm</span>(x1 <span class="sc">~</span> x2))) <span class="sc">~</span> <span class="fu">I</span>(<span class="fu">resid</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x2)))), <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="resources/images/Week03_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>Here we show the residual of y after having removed x2, the linear effect of x2, and the residual of x1 having removed linear effect of x2. As you can see there’s
a very strong relationship left over between y and x1 after having removed the effect of x2.</p>
<p>We want to reiterate we haven’t said what exactly is the right model, the best way to think about that is you have to bring in some of the specific subject matter, or clinical scientific subject matter expertise into your model building exercise. If you’re doing model building with a regular data set where you want interpretable
coefficients getting the team of people some with the right scientific expertise, some with the statistical expertise, and some with the computing expertise is essential.</p>
</div>
</div>
<div id="residuals-again" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Residuals again</h2>
<p>Recall from before that the vertical distances between the observed data points and the fitted regression line are called residuals. We can generalize this idea to the vertical distances between the observed data and the fitted surface in multivariable settings.</p>
</div>
<div id="model-selection" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Model selection</h2>
</div>
<div id="practical-r-exercises-in-swirl-2" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Practical R Exercises in swirl</h2>
<p>During this week of the course you should complete the following lessons in the Regression Models swirl course:</p>
<ol style="list-style-type: decimal">
<li>MultiVar Examples2</li>
<li>MultiVar Examples3</li>
<li>Residuals Diagnostics and Variation</li>
</ol>
</div>
<div id="week-3-quiz" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Week 3 Quiz</h2>
</div>
<div id="optional-practice-exercise-in-regression-modeling" class="section level2" number="3.8">
<h2><span class="header-section-number">3.8</span> (OPTIONAL) Practice exercise in regression modeling</h2>

</div>
</div>
<hr>
<center> 
  <div class="footer">
      All illustrations <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY. </a>
      <br>
      All other materials <a href= "https://creativecommons.org/licenses/by/4.0/"> CC-BY </a> unless noted otherwise.
  </div>
</center>
            </section>

          </div>
        </div>
      </div>
<a href="week-02.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="week-04.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
